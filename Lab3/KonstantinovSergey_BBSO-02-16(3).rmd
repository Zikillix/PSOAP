### *Лабораторная работа №3. Исследование возможностей автоматизации сбора данных о доменах*

--------------------------------------------------------------------------------------------------------------------------------

### *Цель работы*: Собрать информацию о топ 15 доменах в одной из категорий Programming ( 4919 )

--------------------------------------------------------------------------------------------------------------------------------

### *Исходные данные*
1. Ноутбук c OC Windows
2. Ubuntu
3. Google Chrome
4. Github
5. 15 доменов:
 - Monotype.com
 - Linotype.com
 - Fontlibrary.org
 - Clker.com
 - Elated.com
 - Dryicons.com
 - Disneyclips.com
 - Grsites.com
 - Classroomclipart.com
 - Gifrun.com
 - Fontyukle.net
 - Iconfinder.com
 - Thenounproject.com
 - Icon-icons.com
 - Iconarchive.com
   
   
   
--------------------------------------------------------------------------------------------------------------------------------

### *Используемое ПО*
   - Rstudio IDE - отчет
   - nmap
   - dig
   - whois
   - rappalyzer
   
--------------------------------------------------------------------------------------------------------------------------------

### *Собираемые данные*
1. Домен
2. IP
3. IP Netbloc
4. Страна, город
5. Адрес
6. Телефон
7. Хостинг (при наличии)
8. Открытые порты
9. Используемые web-технологии на сайте

--------------------------------------------------------------------------------------------------------------------------------

### *Варианты решений*
1. Собрать информацию вручную с помощью веб-браузера, инструментов whois, dig, nmap и т.д.
2. Использоавть интегрированные инструменты такие как SpiderFoot, Maltego CE, Datasploit, Recon-ng
3. **Самостоятельно разработать (для образовательных целей) автоматизированное решение для сбора информации.
--------------------------------------------------------------------------------------------------------------------------------


### *Ход работы*

```{r, cache=TRUE}
library(tidyverse)
get_sum_df <- function(company_url) {
  country_state <- NA
  dig <- system2('dig', company_url, stdout = TRUE)
  ip <- dig %>%
    grep(pattern = company_url, value = TRUE) %>%
    str_extract(pattern = "\\b(?:[0-9]{1,3}\\.){3}[0-9]{1,3}\\b")
  ip <- ip[!is.na(ip)]
  
  whois <- system2('whois', ip[1], stdout = TRUE)
  phones <- whois %>%
    grep(pattern = "Phone", value = TRUE, ignore.case = TRUE) %>%
    str_squish() %>%
    str_split(pattern = " ") %>%
    data.table::transpose() %>%
    .[[2]] %>%
    unique() %>%
    str_c(collapse = " ")
  
  netblock <- whois %>%
    grep(pattern = "CIDR", value = TRUE, ignore.case = TRUE) %>%
    str_squish() %>%
    str_split(pattern = " ", simplify = TRUE) %>%
    .[-1] %>%
    str_c(collapse = " ")
  
  country <- whois %>%
    grep(pattern = "Country",
         value = TRUE,
         ignore.case = TRUE) %>%
    str_squish() %>%
    str_split(pattern = " ", simplify = TRUE) %>%
    .[-1]
  
  country_state <- whois %>%
    grep(pattern = "State",
         value = TRUE,
         ignore.case = TRUE) %>%
    str_squish() %>%
    str_split(pattern = " ", simplify = TRUE) %>%
    .[-1]
  if(length(country_state)==0) country_state <- NA
  
  address <- whois %>%
    grep(pattern = "address",
         value = TRUE,
         ignore.case = TRUE) %>%
    str_squish() %>%
    str_split(pattern = " ", simplify = TRUE) %>%
    .[-1] %>%
    str_c(collapse = " ")
  
  hosting <- whois %>%
    grep(pattern = "Hosting",
         value = TRUE,
         ignore.case = TRUE) %>%
    str_squish() %>%
    str_split(pattern = " ")
  hosting <- lapply(hosting, collapse = " ", str_c) %>%
    str_c(collapse = " ")
  
  nmap <-
    system2('nmap',
            args = c('-p', '22,21,80,443', ip[1]),
            stdout = TRUE)
  ports <- nmap %>%
    grep(pattern = "open",
         value = TRUE,
         ignore.case = TRUE) %>%
    str_squish() %>%
    str_split(pattern = " ") %>%
    data.table::transpose() %>%
    .[[1]] %>%
    str_c(collapse = " ")
  ip <- str_c(ip,collapse = ' ')
  company_sum <-
    data.frame(
      csum = c(
        company_url,
        ip,
        netblock,
        country,
        country_state,
        address,
        phones,
        hosting,
        ports
      ),
      row.names = c(
        'company_url',
        'ip',
        'netblock',
        'country',
        'country_state',
        'address',
        'phones',
        'hosting',
        'ports'
      )
    )
  company_sum
  
}
urls <- c(("Monotype.com"),("Linotype.com"),("Fontlibrary.org"),("Clker.com"),("Elated.com"),("Dryicons.com"),("Disneyclips.com"),("Grsites.com"),("Classroomclipart.com"),("Gifrun.com"),("Fontyukle.net"),("Iconfinder.com"),("Thenounproject.com"),("Icon-icons.com"),("Iconarchive.com"))
dfs <- lapply(urls, get_sum_df) # применение полученной функции к вектору, на выходе функции - список из одноколоночных датафреймов
result <- bind_cols(dfs) # объединение в один датафрейм
# задаем названия строк
row.names(result) <- c(
        'company_url',
        'ip',
        'netblock',
        'country',
        'country_state',
        'address',
        'phones',
        'hosting',
        'ports'
      )
# задаем названия столбцов из первой строки полученного датафрейма (предварительно переведя в тип character)
colnames(result) <- map(result[1,],as.character) %>% unlist()
# удалим теперь первую строку таблицы - она дублирует названия столбцов
result <- result[-1,]
# Выводим таблицу
knitr::kable(result) 
```



--------------------------------------------------------------------------------------------------------------------------------

###*Используемые web-технологии на сайте*



```{r, cache=TRUE}

library(rappalyzer)
rappalyze("Monotype.com")
rappalyze("Linotype.com")
rappalyze("Fontlibrary.org")
rappalyze("Clker.com")
rappalyze("Elated.com")
rappalyze("Dryicons.com")
rappalyze("Disneyclips.com")
rappalyze("Grsites.com")
rappalyze("Classroomclipart.com")
rappalyze("Gifrun.com")
rappalyze("Fontyukle.net")
rappalyze("Iconfinder.com")
rappalyze("Thenounproject.com")
rappalyze("Icon-icons.com")
rappalyze("Iconarchive.com")
```



--------------------------------------------------------------------------------------------------------------------------------

### *Оценка результата*
	С помощью автоматизированного поиска нам удалось решить задачу по поиску информации наиболее быстрым способом.

--------------------------------------------------------------------------------------------------------------------------------

### *Вывод*
Мы научились собирать информацию о доменах автоматизированным методом, что позволило нам ускорить процесс поиска. 

--------------------------------------------------------------------------------------------------------------------------------

